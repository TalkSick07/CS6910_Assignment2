{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEngt6WAVDYl"
      },
      "outputs": [],
      "source": [
        "#Necessary Libraries\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, BatchNormalization, Dropout, MaxPooling2D, Activation\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb -qqq\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback"
      ],
      "metadata": {
        "id": "rK8FFAaAo5G7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0lQwIo9CYNk"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0SSYgk2KfjI"
      },
      "outputs": [],
      "source": [
        "zip_path = \"/content/drive/MyDrive/Dataset /nature_12K.zip\"\n",
        "!cp \"{zip_path}\" .\n",
        "!unzip -q nature_12K.zip\n",
        "!rm nature_12K.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing the training and testing directories\n",
        "import os \n",
        "Tags = ['Amphibia','Animalia','Arachnida','Aves','Fungi','Insecta','Mammalia','Mollusca','Plantae','Reptilia']\n",
        "no_class = 10\n",
        "train_dir='inaturalist_12K/train/'\n",
        "test_dir='inaturalist_12K/val/'"
      ],
      "metadata": {
        "id": "Ez76_uTd5pVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_86tGbUyVQ9Q"
      },
      "outputs": [],
      "source": [
        "#Generating test data set \n",
        "def test_dataset(batch_size=256,augment_data=False):\n",
        "\n",
        "    if augment_data:\n",
        "        train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                          rotation_range=45,\n",
        "                                          zoom_range=0.2,\n",
        "                                          shear_range=0.2,\n",
        "                                          horizontal_flip=True,\n",
        "                                          validation_split=0.1)\n",
        "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    else:\n",
        "        train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.1)\n",
        "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(train_dir, target_size=(128, 128),batch_size=batch_size,\n",
        "                                                        class_mode=\"categorical\",subset='training', seed=1234)\n",
        "    val_generator = train_datagen.flow_from_directory(train_dir, target_size=(128, 128),batch_size=batch_size,\n",
        "                                                        class_mode=\"categorical\",subset='validation', seed=1234)\n",
        "    test_generator = test_datagen.flow_from_directory(test_dir, target_size=(128, 128), batch_size=batch_size,\n",
        "                                                        class_mode=\"categorical\",seed=1234)\n",
        "    \n",
        "    return train_generator,val_generator, test_generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwazTYfOKRnJ"
      },
      "outputs": [],
      "source": [
        "#Build a small CNN model consisting of 5 convolution layers.\n",
        "\n",
        "def CNN(filters,filter_size, image_size=256,\n",
        "              dropout=0.2,batch_norm=False, dense_size=64, \n",
        "              regpara=0, no_of_classes=10, activation='relu'):\n",
        "\n",
        "    model = Sequential()\n",
        "    for i in range(5):\n",
        "        if(i==0):\n",
        "            model.add(Conv2D(filters=filters[i], kernel_size=filter_size[i], padding = 'same', input_shape = (image_size, image_size, 3),\n",
        "                             kernel_regularizer= regularizers.l2(regpara)))\n",
        "        else:\n",
        "            model.add(Conv2D(filters=filters[i], kernel_size=filter_size[i], padding = 'same',\n",
        "                             kernel_regularizer= regularizers.l2(regpara)))\n",
        "        model.add(Activation(activation))\n",
        "        if batch_norm:\n",
        "            model.add(BatchNormalization())\n",
        "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    \n",
        "    # FC layer\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(dense_size, activation=\"relu\",kernel_regularizer= regularizers.l2(regpara)))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    #Output Layer\n",
        "    model.add(Dense(no_of_classes, activation = \"softmax\"))\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_W8i9RjMUuIq"
      },
      "outputs": [],
      "source": [
        "#Testing the model with the best configuration on test data\n",
        "def test():\n",
        "    \n",
        "    #best_configuration obtained from training and validation\n",
        "        best_kernel_size= [(3,3),(3,3),(3,3),(3,3),(3,3)]\n",
        "        best_weight_decay= 0\n",
        "        best_dropout= 0.4\n",
        "        best_learning_rate= 1e-3\n",
        "        best_activation= 'selu'\n",
        "        best_batch_size= 128\n",
        "        best_batch_norm= True\n",
        "        best_filters= [32,32,32,32,32]\n",
        "        best_data_augment= False\n",
        "        best_dense_size= 64\n",
        "   \n",
        "        model=CNN(filters=best_filters,filter_size=best_kernel_size, image_size=128,\n",
        "                  dropout=best_dropout,batch_norm=best_batch_norm, dense_size=best_dense_size, \n",
        "                  regpara=best_weight_decay, no_of_classes=10, activation=best_activation)\n",
        "    \n",
        "        model.compile(loss = \"categorical_crossentropy\", optimizer = 'adam', metrics=['accuracy'])\n",
        "        train_data,val_data,test_data = test_dataset(batch_size=best_batch_size,augment_data=best_data_augment)\n",
        "        model.fit(train_data, epochs=10,validation_data=val_data)\n",
        "        model.evaluate(test_data, batch_size = best_batch_size)\n",
        "        model.save(\"model-best.h5\")\n",
        "\n",
        "        return model\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=test()"
      ],
      "metadata": {
        "id": "3zV9xO2tB9UX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#taking 30 sample images,3 from each class for visualizing\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import cv2 \n",
        "images=[]\n",
        "tag=[]\n",
        "tag_pred=[]\n",
        "for tg in Tags:\n",
        "    i=0\n",
        "    dir=os.path.join(test_dir,tg)\n",
        "    for img in os.listdir(dir):\n",
        "        if i<3:\n",
        "            image = mpimg.imread(os.path.join(dir,img))\n",
        "            images.append(image)\n",
        "            tag.append(tg)\n",
        "            img_req= cv2.resize(image, (128,128)) / 255.0\n",
        "            prediction = model.predict(img_req.reshape(1,128, 128,3))           #To predict the given image\n",
        "            p=prediction.argmax()                                               #outputs an integer value from 0 to 9\n",
        "            tag_pred.append(Tags[p])\n",
        "            i+=1\n",
        "\n",
        "#Plotting a 10x3 grid with true labels and predicted labels\n",
        "fig = plt.figure(figsize=(10,30))\n",
        "for i in range(30):\n",
        "  img=cv2.resize(images[i],(128,128))\n",
        "  fig.add_subplot(10,3,i+1)\n",
        "  plt.imshow(img)\n",
        "  plt.axis('off')\n",
        "  plt.title('True:'+ tag[i] + ',' + 'Predicted:'+ tag_pred[i],fontdict={'fontsize':10}) \n",
        "wandb.init(entity='nomads',project='CS6910_DL_Assignment2')\n",
        "wandb.log({'Plotting a 10x3 grid with true labels and predicted labels':plt})"
      ],
      "metadata": {
        "id": "DqzMa7VlGU41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "IxN5YzqwH-vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualising all the filters in the first layer of the best model for a random image from the test set.\n",
        "#Reference: https://machinelearningmastery.com/how-to-visualize-filters-and-feature-maps-in-convolutional-neural-networks/\n",
        "\n",
        "#Input is the image to the model \n",
        "#Output is the output from the first convolution layer\n",
        "filter_layer_1 = tf.keras.models.Model(\n",
        "      inputs = model.inputs,                        \n",
        "      outputs = model.get_layer('conv2d_5').output)\n",
        "tag = Tags[2]                                        #To plot the filters for class 2 i.e. 'Arachnida'\n",
        "dir=os.path.join(test_dir,tag)\n",
        "image_name=os.listdir(dir)[0]                        #Loading the test data\n",
        "image_path=(os.path.join(dir,image_name))\n",
        "image=mpimg.imread(image_path)\n",
        "img_req=cv2.resize(image,(128,128))\n",
        "idx = np.expand_dims(img_req, axis=0)                #Expand the shape of the Image array\n",
        "inputs = tf.cast(idx, tf.float32)                    #To cast a tensor into float type\n",
        "out = filter_layer_1(inputs)[0]                      \n",
        "\n",
        "#Plotting the 32 filters in 8x4 grid\n",
        "no_of_filters= 32\n",
        "plt.figure(figsize=(20,20))\n",
        "for i in range(no_of_filters):\n",
        "    f = out[:, :, i]\n",
        "    # plot each channel separately\n", 
        "    for j in range(3):\n",
        "        # specify subplot and turn of axis\n",
        "        ax = plt.subplot(8, 4, i+1)\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "        plt.imshow(f)\n",
        "# show the figure\n",
        "#plt.show()\n",
        "wandb.init(entity='nomads',project='CS6910_DL_Assignment2')\n",
        "wandb.log({'Visualising all the filters in the first layer':plt})"
      ],
      "metadata": {
        "id": "hHoD-Urqfe89"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "DL_Assignment2A_testing.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
