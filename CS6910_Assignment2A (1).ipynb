{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS6910_Assignment2A.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q1. Build a small CNN model consisting of 5 convolution layers. Each convolution layer would be followed by a ReLU activation and a max pooling layer."
      ],
      "metadata": {
        "id": "y7v1yMg-QpOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Necessary Libraries\n",
        "import numpy as np\n",
        "import tensorflow\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, BatchNormalization, Dropout, MaxPooling2D, Activation\n"
      ],
      "metadata": {
        "id": "zMzragLCFdrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mounting the drive to access the dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "X4DPUehUFm-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Unzipping the nature_12K.zip dataset\n",
        "zip_path = \"/content/drive/MyDrive/Dataset /nature_12K.zip\"\n",
        "!cp \"{zip_path}\" .\n",
        "!unzip -q nature_12K.zip\n",
        "!rm nature_12K.zip"
      ],
      "metadata": {
        "id": "d_NmlzlnFzZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Installing the wandb library\n",
        "\n",
        "!pip install wandb -qqq\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback"
      ],
      "metadata": {
        "id": "gDMakTjuF34v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()"
      ],
      "metadata": {
        "id": "DP-vav_OF_2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing the training and testing directories\n",
        "import os \n",
        "Tags = ['Amphibia','Animalia','Arachnida','Aves','Fungi','Insecta','Mammalia','Mollusca','Plantae','Reptilia']\n",
        "no_class = 10\n",
        "train_dir='inaturalist_12K/train/'\n",
        "test_dir='inaturalist_12K/val/'"
      ],
      "metadata": {
        "id": "LD323r8vGHTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualizing images of each class \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 \n",
        "import matplotlib.image as mpimg\n",
        "fig = plt.figure(figsize=(20,8))\n",
        "i=1\n",
        "for tag in Tags:\n",
        "  dir=os.path.join(train_dir,tag)\n",
        "  image_name=os.listdir(dir)[0]\n",
        "  image_path=os.path.join(dir,image_name)\n",
        "  img=mpimg.imread(image_path)\n",
        "  img_req=cv2.resize(img,(128,128)) \n",
        "  fig.add_subplot(2,5,i)\n",
        "  plt.imshow(img_req)\n",
        "  plt.axis('off')\n",
        "  plt.title(tag)\n",
        "  i+=1   \n"
      ],
      "metadata": {
        "id": "SKQgrRkLGIVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating the dataset for training and validation\n",
        "def train_val__test_data_generation(batch_size=256,augment_data=False):\n",
        "    #Augmenting the data to avoid overfitting\n",
        "    if augment_data:\n",
        "        train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                          rotation_range=45,\n",
        "                                          zoom_range=0.2,\n",
        "                                          shear_range=0.2,\n",
        "                                          validation_split=0.1,\n",
        "                                          horizontal_flip=True,\n",
        "                                          vertical_flip=False)\n",
        "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    else:\n",
        "        train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.1)\n",
        "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "    #Generating data batch by batch in order to make the model faster to run the dataset\n",
        "    train_generator = train_datagen.flow_from_directory(train_dir, target_size=(128,128), batch_size=batch_size, subset=\"training\")\n",
        "    val_generator = train_datagen.flow_from_directory(train_dir, target_size=(128,128), batch_size=batch_size, subset=\"validation\")\n",
        "    test_generator = test_datagen.flow_from_directory(test_dir, target_size=(128,128), batch_size=batch_size)\n",
        "    \n",
        "    return train_generator, val_generator, test_generator"
      ],
      "metadata": {
        "id": "JZunh5IDGLJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator, val_generator, test_generator = train_val__test_data_generation(batch_size=64,augment_data=True)"
      ],
      "metadata": {
        "id": "DD7jQLq9GSKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Building a CNN model consisting of 5 convolution layers.\n",
        "\n",
        "def CNN(filters,filter_size, image_size=128,\n",
        "              dropout=0.2,batch_norm=False, dense_size=64, \n",
        "              regpara=0, no_of_classes=10, activation='relu'):\n",
        "\n",
        "    model = Sequential()\n",
        "    for i in range(5):\n",
        "        if(i==0): #Input Layer needs the image as the input\n",
        "            model.add(Conv2D(filters=filters[i], kernel_size=filter_size[i], padding = 'same', input_shape = (image_size, image_size, 3),\n",
        "                             kernel_regularizer= regularizers.l2(regpara)))\n",
        "        else:\n",
        "            model.add(Conv2D(filters=filters[i], kernel_size=filter_size[i], padding = 'same',\n",
        "                             kernel_regularizer= regularizers.l2(regpara)))\n",
        "        #Adding the Activation function\n",
        "        model.add(Activation(activation))\n",
        "        #Batch normalization after each activation\n",
        "        if batch_norm:\n",
        "            model.add(BatchNormalization())\n",
        "        #Max Pooling after each layer\n",
        "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    \n",
        "    # FullyConnected layer\n",
        "    model.add(Flatten()) #flatten to get the final feature vector\n",
        "    model.add(Dense(dense_size, activation=\"relu\",kernel_regularizer= regularizers.l2(regpara)))\n",
        "    model.add(Dropout(dropout)) #Adding dropout for better regularization\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    #Output Layer\n",
        "    model.add(Dense(no_of_classes, activation = \"softmax\")) #using softmax since we are building a classifier  \n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "s2PUBHzFGtTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Configurations to find out the best hyperparameters out of them\n",
        "sweep_config = {\n",
        "    'method': 'bayes', \n",
        "    'metric': {\n",
        "      'name': 'val_accuracy',\n",
        "      'goal': 'maximize'   \n",
        "    },\n",
        "    'parameters': {\n",
        "        'kernel_size':{\n",
        "            'values': [[(2,2),(2,2),(2,2),(2,2),(2,2)], [(3,3),(3,3),(3,3),(3,3),(3,3)],[(6,6),(5,5),(4,4),(3,3),(2,2)],[(2,2),(3,3),(4,4),(5,5),(6,6)]]\n",
        "        },\n",
        "        'weight_decay': {\n",
        "            'values': [0, 0.0005, 0.005]\n",
        "        },\n",
        "        'dropout': {\n",
        "            'values': [0, 0.2, 0.3, 0.4]\n",
        "        },\n",
        "        'learning_rate': {\n",
        "            'values': [1e-3, 1e-4]\n",
        "        },\n",
        "        'activation': {\n",
        "            'values': ['relu','selu','elu']\n",
        "        },\n",
        "        'batch_norm':{\n",
        "            'values': [True,False]\n",
        "        },\n",
        "        'filters':{\n",
        "            'values': [[32,32,32,32,32],[32,64,128,256,512],[32,16,8,4,2],[512,256,128,64,32]]\n",
        "        },\n",
        "        'augment_data': {\n",
        "            'values': [True,False]\n",
        "        },\n",
        "        'batch_size': {\n",
        "            'values': [32, 64, 128, 256]\n",
        "        },\n",
        "        'dense_size':{\n",
        "            'values': [64, 128, 256, 512]\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "WRGyqmhzGxXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training the CNN model using the sweep configurations\n",
        "def train():\n",
        "    #default configurations\n",
        "    config_defaults = {\n",
        "        'kernel_size': [(3,3),(3,3),(3,3),(3,3),(3,3)],\n",
        "        'weight_decay': 0.005,\n",
        "        'dropout': 0.2,\n",
        "        'learning_rate': 1e-3,\n",
        "        'activation': 'relu',\n",
        "        'batch_size': 64,\n",
        "        'epochs': 10,\n",
        "        'batch_norm': True,\n",
        "        'filters' : [32,32,32,32,32],\n",
        "        'augment_data': True,\n",
        "        'dense_size': 256,\n",
        "        'seed': 1234,\n",
        "        'no_of_classes': 10\n",
        "    }\n",
        "\n",
        "    # Initialize a new wandb run\n",
        "    wandb.init(config=config_defaults)\n",
        "    #config will store the hyperparameters\n",
        "    config = wandb.config\n",
        "    wandb.run.name = 'dense_size_'+ str(config.dense_size)+'_bs_'+str(config.batch_size)+'_ac_'+ config.activation\n",
        "\n",
        "    #calling the CNN model with the sweep configurations to build the model\n",
        "    model=CNN(filters=config.filters,filter_size=config.kernel_size, image_size=128,\n",
        "              dropout=config.dropout,batch_norm=config.batch_norm, dense_size=config.dense_size, \n",
        "              regpara=config.weight_decay, no_of_classes=config.no_of_classes, activation=config.activation )\n",
        "    #using the Adam optimizer\n",
        "    optimizer = Adam(learning_rate=config.learning_rate, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "    model.compile(loss = \"categorical_crossentropy\", optimizer = optimizer, metrics=['accuracy'])\n",
        "\n",
        "    train_generator, val_generator, test_generator = train_val__test_data_generation(batch_size=config.batch_size,augment_data=config.augment_data)\n",
        "    #To train the model and store the best validation accuracy\n",
        "    hist=model.fit(train_generator, epochs=config.epochs, validation_data=val_generator, callbacks=[WandbCallback()])\n",
        "    val_acc=max(hist.history['val_accuracy'])\n",
        "    params={'batch_norm':config.batch_norm,'augmentation':config.augment_data,'dropout':config.dropout,\n",
        "            'filter_architecture':config.filters,'kernel_size':config.kernel_size,'val_acc':val_acc}\n",
        "    wandb.log(params)"
      ],
      "metadata": {
        "id": "2bUL853wG4oV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project=\"CS6910_DL_Assignment2\", entity=\"nomads\")"
      ],
      "metadata": {
        "id": "gLT2_q8LG_-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.agent('twsg746e', train, count = 50)"
      ],
      "metadata": {
        "id": "_th4GZNDHWMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GHF0X9WfInSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IqHng0HpIpF-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}